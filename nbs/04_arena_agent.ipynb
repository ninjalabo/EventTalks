{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc91b506a64af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp arena_agent\n",
    "#| test: false\n",
    "\n",
    "\n",
    "#\"Chat UI + LLM agent that talks to FastMCP tools.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e83458a3b3e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "from __future__ import annotations\n",
    "import asyncio, html, json, os\n",
    "from typing import AsyncIterator, List, Dict, Tuple, Any\n",
    "\n",
    "from fastapi import FastAPI, Request, status\n",
    "from fastapi.responses import HTMLResponse\n",
    "from fasthtml import FastHTML\n",
    "from fasthtml.common import Div, Form, Input, Button, H1\n",
    "from sse_starlette.sse import EventSourceResponse\n",
    "from agents import Agent, Runner\n",
    "from agents.mcp import MCPServerSse\n",
    "from fasthtml.common import (Body, Button, Div, Form, Group, H1, H2, Input,\n",
    "                             Link, NotStr, Script, Style)\n",
    "from typing import List\n",
    "import datetime\n",
    "from dataclasses import dataclass\n",
    "import httpx, asyncio, yaml, re\n",
    "from functools import lru_cache\n",
    "from typing import List, Dict\n",
    "from agents import ToolCallItem\n",
    "from monsterui.all import Theme \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f3a5aa8bc825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "# ── Config (env-vars for docker-compose) ───────────────────────────────────\n",
    "MCP_URL        = os.getenv(\"MCP_URL\", \"http://tools:9001/sse\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae888f38bea5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "history: list[dict] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7861f46d1c6d9d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    " \n",
    "@dataclass\n",
    "class EventContext:\n",
    "    event_date_time: datetime\n",
    "    event_title: str\n",
    "    event_description: str\n",
    "    \n",
    "EventContext = EventContext(event_date_time=\"04.10.2025 12:00:00\", \n",
    "                            event_title=\"Hockey match KIEKKO-ESPOO vs KÄRPÄT\", \n",
    "                            event_description=\n",
    "                            \"Liiga regular-season showdown at Metro Areena • Doors open 11:15 \"                        \"Sustainable transport encouraged \"                                                        \"(metro: Urheilupuisto, bike racks outside Gate B).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50279efb695c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "# ── FastHTML shell with Tailwind + HTMX + SSE ext ─────────────────────────\n",
    "app_html = FastHTML(\n",
    "    hdrs=Theme.zinc.headers() + [\n",
    "        Script(src=\"https://cdn.tailwindcss.com\"),\n",
    "\n",
    "        # daisyUI (optional)\n",
    "        Script(src=\"https://cdn.jsdelivr.net/npm/daisyui@4.10.2/dist/full.min.js\"),\n",
    "\n",
    "        # HTMX SSE extension (HTMX core auto-injected via live=True)\n",
    "        Script(src=\"https://unpkg.com/htmx-ext-sse@2.2.3/dist/sse.js\"),\n",
    "\n",
    "    ],  \n",
    "    live=True,\n",
    "    html_attrs={\"data-theme\": \"dark\", \"class\": \"bg-gray-50 text-gray-700\"},\n",
    ")\n",
    "\n",
    "# FastAPI wrapper so uvicorn can find the ASGI app\n",
    "app = FastAPI(title=\"Arena Buddy\", docs_url=None)\n",
    "app.mount(\"/\", app_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4140c8785f557c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "# ── In-memory chat log ────────────────────────────────────────────────────\n",
    "MSG: List[Dict[str, str]] = []\n",
    "MSG_LOCK = asyncio.Lock()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678d0ac21df0683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "# ── UI helpers ─────────────────────────────────────────────────────────────\n",
    "def _chat_bubble(idx: int, **hx):\n",
    "    role, txt = MSG[idx][\"role\"], MSG[idx][\"content\"] or \"…\"\n",
    "    side   = \"chat-end\" if role == \"user\" else \"chat-start\"\n",
    "    bubble = \"bg-sky-700 text-white\" if role == \"assistant\" else \"bg-gray-200\"\n",
    "    return Div(\n",
    "        Div(role, cls=\"chat-header text-xs text-gray-500\"),\n",
    "        Div(txt if role == \"user\" else html.unescape(txt),\n",
    "            cls=f\"chat-bubble {bubble}\", **hx),\n",
    "        cls=f\"chat {side}\", id=f\"m{idx}\",\n",
    "    )\n",
    "\n",
    "def _chat_input():\n",
    "    return Input(\n",
    "        id=\"msgin\",                    \n",
    "        name=\"msg\",\n",
    "        type=\"text\",\n",
    "        autocomplete=\"off\",\n",
    "        placeholder=\"Type your question…\",\n",
    "        cls=\"input input-bordered w-full\",\n",
    "        hx_swap_oob=\"true\",             \n",
    "        onkeyup=\"event.key==='Enter' && this.form.requestSubmit()\",\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31036d7caaa584ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "# ── Home page ─────────────────────────────────────────────────────────────\n",
    "@app_html.get(\"/\")\n",
    "async def home():\n",
    "    ui = Div(\n",
    "        Div(id=\"toaster\", cls=\"toast toast-top toast-end fixed z-50\"),\n",
    "        H1(\"Arena Buddy\", cls=\"text-3xl font-bold mb-4\"),\n",
    "        Div(id=\"chatlog\",\n",
    "            cls=\"space-y-3 mb-4 h-[70vh] overflow-y-auto bg-base-200 p-4 rounded-box\"),\n",
    "        Form(\n",
    "            Div(_chat_input(),\n",
    "                Button(\"Send ✈\", cls=\"btn btn-primary ml-2\"),\n",
    "                cls=\"flex\"),\n",
    "            hx_post=\"/send\",          \n",
    "            hx_target=\"#chatlog\",\n",
    "            hx_swap=\"beforeend\",\n",
    "        ),\n",
    "        cls=\"max-w-2xl mx-auto p-6\",\n",
    "    )\n",
    "    return ui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f6cb7ebb0776e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "mainAgent_instruction = f\"\"\"\n",
    "╭─────────────────────────────────────────────────────────────╮\n",
    "│ 🎟  EVENT CONTEXT                                           │\n",
    "╰─────────────────────────────────────────────────────────────╯\n",
    "• **When**   : {EventContext.event_date_time}\n",
    "• **What**   : {EventContext.event_title}\n",
    "• **Details**: {EventContext.event_description}\n",
    "\n",
    "Your single goal → get the user there **on time** with the **lowest possible CO₂** footprint.\n",
    "\n",
    "────────────────────────────────────────────────────────────────\n",
    "HOW TO THINK & RESPOND\n",
    "────────────────────────────────────────────────────────────────\n",
    "1. **Understand** the latest user message + full history.\n",
    "2. **Plan** a short chain-of-thought *silently* (don’t reveal it).\n",
    "3. **Pick or mount tools**\n",
    "   • If an existing tool fits (e.g. `walk_route`, `bike_route`,\n",
    "     `pt_route`, `car_route`, `nearest_parking_ids`, etc.) – call it.\n",
    "   • Else call  \n",
    "     `quick_mount_openapi(\"<keywords>\")`  \n",
    "     then immediately call the needed REST operation.\n",
    "4. **Compare modes**  \n",
    "   • If any proposed leg is high-carbon (car, taxi, flight),\n",
    "     suggest at least one greener alternative and **quantify the saving**\n",
    "     (e.g. “Train cuts ≈80 % CO₂ vs car for this distance”).\n",
    "5. **Summarise results** in clear bullet points:\n",
    "   • departure / arrival time, duration, CO₂ estimate, cost (if known).\n",
    "6. **Humour & tone**  \n",
    "   • Every 3-4 replies, add a light joke or emoji (PG-13, relevant).\n",
    "7. **Car users**  \n",
    "   • If the user insists on driving, call\n",
    "     `nearest_parking_ids` ➜ `parking_status`\n",
    "     and gently remind why public transport is greener.\n",
    "8. **Error handling**  \n",
    "   • If a tool raises *ToolError* mentioning “API key”,\n",
    "     politely ask the user for the key **or** suggest a free workaround.\n",
    "9. **Final formatting**\n",
    "   • After you have the textual answer, wrap it in a MonsterUI block:\n",
    "     ```html\n",
    "     <div class=\"card shadow-lg bg-base-200\">\n",
    "       … route summary …\n",
    "       <button class=\"btn btn-primary\">Open map</button>\n",
    "     </div>\n",
    "     ```\n",
    "   • Use simple MonsterUI / DaisyUI classes (`card`, `btn`, `badge`, …).\n",
    "10. **Be concise** – maximum 4-6 sentences + the card.\n",
    "\n",
    "(You may omit steps that are not relevant to the user’s request.)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295ff0c0b0a5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "\n",
    "from agents import Agent, RunContextWrapper, RunHooks, Runner, Tool, Usage, function_tool\n",
    "from typing import Callable, Any\n",
    "\n",
    "class ToolChatHook(RunHooks[None]):\n",
    "    \"\"\"\n",
    "    Fires push(msg) on every tool start / end / error so the UI can\n",
    "    display a live notification in the chat area.\n",
    "    \"\"\"\n",
    "    def __init__(self, push: Callable[[str], None]):\n",
    "        self._push = push\n",
    "        \n",
    "    async def on_start(self, context, agent) -> None:\n",
    "        \"\"\"Called once when the whole agent run begins.\"\"\"\n",
    "        self._push(\"🤖 _thinking…_\")\n",
    "\n",
    "    async def on_end(self, context, agent, result) -> None:\n",
    "        \"\"\"Called once after the final answer has been produced.\"\"\"\n",
    "        # Nothing fancy for now; you could log token usage here\n",
    "        pass        \n",
    "        \n",
    "\n",
    "    async def on_tool_start(self, context, agent, tool) -> None:\n",
    "       self._push(f\"{tool.name}  started\")\n",
    "\n",
    "    async def on_tool_end(self, context, agent, tool, result) -> None:\n",
    "        self._push(f\"✔ {tool.name} finished\")\n",
    "        self._push(f\"result: {result}\")\n",
    "        \n",
    "\n",
    "    async def on_tool_error(self, context, agent, tool, error) -> None:\n",
    "        self._push(f\"⚠ {tool.name} failed: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5887d380bcbf24d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "from agents import Agent, Runner, trace\n",
    "from agents.mcp import MCPServerSse\n",
    "\n",
    "async def _assistant_html(user_prompt: str, push: Callable[[str], None]) -> tuple[str, list[str]]:\n",
    "    \"\"\"\n",
    "    ①   mount / call tools as needed\n",
    "    ②   craft the plain-text answer\n",
    "    ③   wrap it in MonsterUI HTML\n",
    "    returns (html_block, [\"tool: output\", …])\n",
    "    \"\"\"\n",
    "  \n",
    "\n",
    "    async with MCPServerSse(name=\"ui\", params={\"url\": MCP_URL}, client_session_timeout_seconds=30) as srv:\n",
    "        agent = Agent(\n",
    "            name=\"Main Agent\",\n",
    "            instructions=mainAgent_instruction,\n",
    "            mcp_servers=[srv],\n",
    "            hooks=ToolChatHook(push),\n",
    "            model=\"o3\"\n",
    "        )\n",
    "\n",
    "        # ── build the initial input list (first user turn) ───────────────\n",
    "        input_items: list = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "        with trace(workflow_name=\"Arena-3-step\"):\n",
    "            # ①  Mount or use step\n",
    "            input_items.append({\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"If no suitable tool exists, call quick_mount_openapi, \"\n",
    "                    \"then the required operation. Summarise the result.\"\n",
    "                ),\n",
    "            })\n",
    "            res1 = await Runner.run(agent, input_items)\n",
    "\n",
    "\n",
    "            # ②  Natural-language answer\n",
    "            input_items = res1.to_input_list()         \n",
    "            res2 = await Runner.run(agent, input_items)\n",
    "\n",
    "\n",
    "            # ③  MonsterUI formatting\n",
    "            input_items = res2.to_input_list()\n",
    "            input_items.append({\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"Take the previous assistant answer and wrap it in a MonsterUI card.\\n\"\n",
    "        \"—  use <div class='card bg-base-300 text-base-100 shadow-lg p-4 space-y-3'>\\n\"\n",
    "        \"—  put the answer itself inside <p class='whitespace-pre-wrap'> … </p>\\n\"\n",
    "        \"—  try to make every time different cards \\n\"\n",
    "                    \"- add funny images connected to hokey, CO2 etc \\n\"\n",
    "        \"—  if you need an action, add\\n\"\n",
    "        \"     <button class='btn btn-primary' \"\n",
    "        \"             hx-post='/open-map' hx-target='#toaster' hx-swap='afterbegin'>\"\n",
    "        \"Open map 🗺️</button>\\n\"\n",
    "        \"Return **HTML only** – no markdown fences, no extra text.\"\n",
    "                ),\n",
    "            })\n",
    "            res3 = await Runner.run(agent, input_items)\n",
    "            \n",
    "\n",
    "    return res3.final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b23b482281d1808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "# ── /send endpoint ────────────────────────────────────────────────────────\n",
    "@app_html.post(\"/send\")\n",
    "async def send(request: Request):\n",
    "    form   = await request.form()\n",
    "    prompt = str(form.get(\"msg\", \"\")).strip()\n",
    "    if not prompt:\n",
    "        return HTMLResponse(\"\", status_code=status.HTTP_204_NO_CONTENT)\n",
    "\n",
    "    async with MSG_LOCK:\n",
    "        MSG.extend([\n",
    "            {\"role\": \"user\",      \"content\": html.escape(prompt)},\n",
    "            {\"role\": \"assistant\", \"content\": \"\"},\n",
    "        ])\n",
    "        idx_user, idx_asst = len(MSG) - 2, len(MSG) - 1\n",
    "\n",
    "    return (\n",
    "        _chat_bubble(idx_user).__html__() +\n",
    "        _chat_bubble(\n",
    "            idx_asst,\n",
    "            hx_ext=\"sse\",\n",
    "            sse_connect=f\"/stream/{idx_asst}\",\n",
    "            sse_swap=\"message\",\n",
    "            sse_close=\"close\",\n",
    "            hx_swap=\"innerHTML\",\n",
    "        ).__html__() +\n",
    "        _chat_input().__html__()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1001f4191f15d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "from starlette.responses import StreamingResponse     \n",
    "\n",
    "# ── helpers --------------------------------------------------------\n",
    "def _sse(event: str, payload: str) -> str:\n",
    "    \"\"\"\n",
    "    Return one correctly-formatted Server-Sent-Events block.\n",
    "\n",
    "    Each logical message must be terminated with a *blank* line, otherwise\n",
    "    the browser keeps buffering and the event never reaches the JS side.\n",
    "    \"\"\"\n",
    "    # HTMX’ sse.js is happy with plain HTML, so we don’t wrap in JSON here.\n",
    "    body = \"\\n\".join(f\"data: {line}\" for line in payload.splitlines())\n",
    "    return f\"event: {event}\\n{body}\\n\\n\"\n",
    "\n",
    "\n",
    "async def _stream_reply(idx: int) -> AsyncIterator[str]:  # noqa: C901 – acceptable\n",
    "    async with MSG_LOCK:\n",
    "        if idx <= 0 or idx >= len(MSG):\n",
    "            return \n",
    "    prompt_html = MSG[idx - 1][\"content\"]\n",
    "\n",
    "    q: asyncio.Queue[str] = asyncio.Queue()\n",
    "\n",
    "    # push() will be handed to ToolChatHook and to the agent itself\n",
    "    def push(msg: str) -> None:  \n",
    "        q.put_nowait(_sse(\"message\", msg))\n",
    "\n",
    "    async def _run() -> None:\n",
    "        try:\n",
    "            reply_html = await _assistant_html(prompt_html, push)\n",
    "        except Exception as exc:\n",
    "            reply_html = f\"⚠ Internal error: {exc}\"\n",
    "        await q.put(_sse(\"message\", reply_html))     # final HTML card\n",
    "        await q.put(\"event: close\\ndata:\\n\\n\")       # tell HTMX to close\n",
    "\n",
    "    asyncio.create_task(_run()) \n",
    "    \n",
    "    # ⬅️  *this* is what StreamingResponse must consume\n",
    "    async def streamer() -> AsyncIterator[str]:\n",
    "        while True:                   # blocks until the queue gets data\n",
    "            yield await q.get()\n",
    "\n",
    "    return streamer()                 # ← DON’T forget this!\n",
    "\n",
    "# ── /stream/{idx} endpoint (SSE) ------------------------------------------\n",
    "@app_html.get(\"/stream/{idx}\")\n",
    "async def stream(idx: int):\n",
    "    \"\"\"\n",
    "    Streaming endpoint used by the chat bubbles (`hx-ext=\"sse\"`).\n",
    "    HTMX opens the connection, waits for the first “message” event,\n",
    "    swaps the payload into the bubble, then receives a “close” event\n",
    "    and disposes the EventSource.\n",
    "    \"\"\"\n",
    "    generator = await _stream_reply(idx)   # get the AsyncIterator ✅\n",
    "    if generator is None:                  # invalid idx guard\n",
    "        return HTMLResponse(\n",
    "            status_code=status.HTTP_204_NO_CONTENT\n",
    "        )\n",
    "    return StreamingResponse(\n",
    "       generator,\n",
    "        media_type=\"text/event-stream\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b7b018cad250eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "from monsterui.franken import ModalHeader, ModalBody, Modal\n",
    "from fastapi.responses import HTMLResponse\n",
    "\n",
    "import json\n",
    "\n",
    "LEAFLET_CSS  = \"https://unpkg.com/leaflet@1.9.4/dist/leaflet.css\"\n",
    "LEAFLET_JS   = \"https://unpkg.com/leaflet@1.9.4/dist/leaflet.js\"\n",
    "\n",
    "@app_html.post(\"/open-map\")\n",
    "async def open_map(latlngs: list[list[float]] = Form(...)) -> HTMLResponse:\n",
    "    \"\"\"\n",
    "    `latlngs` must be a list like [[lat, lon], [lat, lon], …]\n",
    "    (HTMX will POST it as a JSON string – see §2 below).\n",
    "    \"\"\"\n",
    "    coords_js = json.dumps(latlngs)     # embed safely in <script>\n",
    "\n",
    "    html = Modal(\n",
    "        ModalHeader(\"Route preview 🗺️\"),\n",
    "        ModalBody(\n",
    "            \"<div id='map' class='w-full h-80 rounded-xl'></div>\",\n",
    "            as_html=True\n",
    "        ),\n",
    "        open=True,                          # open immediately\n",
    "    ).__html__() + f\"\"\"\n",
    "    <link rel=\"stylesheet\" href=\"{LEAFLET_CSS}\"/>\n",
    "    <script src=\"{LEAFLET_JS}\"></script>\n",
    "    <script>\n",
    "      (function () {{\n",
    "        const coords = {coords_js};\n",
    "        const map = L.map('map', {{ zoomControl:false }})\n",
    "                     .fitBounds(coords);\n",
    "        L.tileLayer('https://tile.openstreetmap.org/{{z}}/{{x}}/{{y}}.png',\n",
    "                     {{ attribution:'© OSM' }}).addTo(map);\n",
    "        L.polyline(coords, {{ color:'#2563eb', weight:5 }}).addTo(map);\n",
    "      }})();\n",
    "    </script>\n",
    "    \"\"\"\n",
    "\n",
    "    return HTMLResponse(html, status_code=200, media_type=\"text/html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5619052a6610b0af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce267279ad7374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bf72f6e579a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "id": "73e6490ebbcd434d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
