{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc91b506a64af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Chat UI + LLM agent that talks to FastMCP tools.'"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| default_exp arena_agent\n",
    "#| test: false\n",
    "\n",
    "\n",
    "\"Chat UI + LLM agent that talks to FastMCP tools.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e83458a3b3e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "from __future__ import annotations\n",
    "import asyncio, html, json, os\n",
    "from typing import AsyncIterator, List, Dict\n",
    "\n",
    "from fastapi import FastAPI, Request, status\n",
    "from fastapi.responses import HTMLResponse\n",
    "from fasthtml import FastHTML\n",
    "from fasthtml.common import Div, Form, Input, Button, H1\n",
    "from sse_starlette.sse import EventSourceResponse\n",
    "\n",
    "\n",
    "from DataTalks.parking_tools import parking_status, nearest_parking_ids\n",
    "from agents import Agent, Runner\n",
    "from agents.mcp import MCPServerSse\n",
    "from fasthtml.common import (Body, Button, Div, Form, Group, H1, H2, Input,\n",
    "                             Link, NotStr, Script, Style)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f3a5aa8bc825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "# ── Config (env-vars for docker-compose) ───────────────────────────────────\n",
    "MCP_URL        = os.getenv(\"MCP_URL\", \"http://tools:9001/sse\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50279efb695c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "# ── FastHTML shell with Tailwind + HTMX + SSE ext ─────────────────────────\n",
    "app_html = FastHTML(\n",
    "    hdrs=(\n",
    "        Script(src=\"https://cdn.tailwindcss.com\"),\n",
    "\n",
    "        # daisyUI (optional)\n",
    "        Script(src=\"https://cdn.jsdelivr.net/npm/daisyui@4.10.2/dist/full.min.js\"),\n",
    "\n",
    "        # HTMX SSE extension (HTMX core auto-injected via live=True)\n",
    "        Script(src=\"https://unpkg.com/htmx-ext-sse@2.2.3/dist/sse.js\"),\n",
    "\n",
    "        # Adaptive Cards Web Component\n",
    "        Script(src=\"https://unpkg.com/adaptivecards@2.8.0/dist/adaptivecards.min.js\"),\n",
    "        # Adaptive Cards Web Component\n",
    "        Script(src=\"https://unpkg.com/adaptivecards@2.8.0/dist/adaptivecards-webcomponent.js\"),\n",
    "    ),  # close hdrs tuple\n",
    "    live=True,\n",
    "    html_attrs={\"data-theme\": \"dark\", \"class\": \"bg-gray-50 text-gray-700\"},\n",
    ")\n",
    "\n",
    "# FastAPI wrapper so uvicorn can find the ASGI app\n",
    "app = FastAPI(title=\"Arena Buddy\", docs_url=None)\n",
    "app.mount(\"/\", app_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4140c8785f557c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "# ── In-memory chat log ────────────────────────────────────────────────────\n",
    "MSG: List[Dict[str, str]] = []\n",
    "MSG_LOCK = asyncio.Lock()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678d0ac21df0683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "# ── UI helpers ─────────────────────────────────────────────────────────────\n",
    "def _chat_bubble(idx: int, **hx):\n",
    "    role, txt = MSG[idx][\"role\"], MSG[idx][\"content\"] or \"…\"\n",
    "    side   = \"chat-end\" if role == \"user\" else \"chat-start\"\n",
    "    bubble = \"bg-sky-700 text-white\" if role == \"assistant\" else \"bg-gray-200\"\n",
    "    return Div(\n",
    "        Div(role, cls=\"chat-header text-xs text-gray-500\"),\n",
    "        Div(txt if role == \"user\" else html.unescape(txt),\n",
    "            cls=f\"chat-bubble {bubble}\", **hx),\n",
    "        cls=f\"chat {side}\", id=f\"m{idx}\",\n",
    "    )\n",
    "\n",
    "def _chat_input():\n",
    "    return Input(\n",
    "        id=\"msgin\",                    \n",
    "        name=\"msg\",\n",
    "        type=\"text\",\n",
    "        autocomplete=\"off\",\n",
    "        placeholder=\"Type your question…\",\n",
    "        cls=\"input input-bordered w-full\",\n",
    "        hx_swap_oob=\"true\",             \n",
    "        onkeyup=\"event.key==='Enter' && this.form.requestSubmit()\",\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31036d7caaa584ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "# ── Home page ─────────────────────────────────────────────────────────────\n",
    "@app_html.get(\"/\")\n",
    "async def home():\n",
    "    ui = Div(\n",
    "        H1(\"Arena Buddy\", cls=\"text-3xl font-bold mb-4\"),\n",
    "        Div(id=\"chatlog\",\n",
    "            cls=\"space-y-3 mb-4 h-[70vh] overflow-y-auto bg-base-200 p-4 rounded-box\"),\n",
    "        Form(\n",
    "            Div(_chat_input(),\n",
    "                Button(\"Send ✈\", cls=\"btn btn-primary ml-2\"),\n",
    "                cls=\"flex\"),\n",
    "            hx_post=\"/send\",          \n",
    "            hx_target=\"#chatlog\",\n",
    "            hx_swap=\"beforeend\",\n",
    "        ),\n",
    "        cls=\"max-w-2xl mx-auto p-6\",\n",
    "    )\n",
    "    return ui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4763c8378767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "# ── LLM helper ─────────────────────────────────────────────────────────────\n",
    "async def _assistant_html(prompt: str) -> str:\n",
    "    async with MCPServerSse(name=\"ui\", params={\"url\": MCP_URL}) as srv:\n",
    "        agent = Agent(\n",
    "            \"assistant\",\n",
    "            instructions=(\n",
    "                \"You help users reach Metro Areena Espoo with the \"\n",
    "                \"lowest-emission mode possible. Use provided tools.\"\n",
    "            ),\n",
    "            mcp_servers=[srv]    \n",
    "        )\n",
    "        res = await Runner.run(starting_agent=agent, input=prompt)\n",
    "        return res.final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b23b482281d1808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "# ── /send endpoint ────────────────────────────────────────────────────────\n",
    "@app_html.post(\"/send\")\n",
    "async def send(request: Request):\n",
    "    form   = await request.form()\n",
    "    prompt = str(form.get(\"msg\", \"\")).strip()\n",
    "    if not prompt:\n",
    "        return HTMLResponse(\"\", status_code=status.HTTP_204_NO_CONTENT)\n",
    "\n",
    "    async with MSG_LOCK:\n",
    "        MSG.extend([\n",
    "            {\"role\": \"user\",      \"content\": html.escape(prompt)},\n",
    "            {\"role\": \"assistant\", \"content\": \"\"},\n",
    "        ])\n",
    "        idx_user, idx_asst = len(MSG) - 2, len(MSG) - 1\n",
    "\n",
    "    return (\n",
    "        _chat_bubble(idx_user).__html__() +\n",
    "        _chat_bubble(\n",
    "            idx_asst,\n",
    "            hx_ext=\"sse\",\n",
    "            sse_connect=f\"/stream/{idx_asst}\",\n",
    "            sse_swap=\"message\",\n",
    "            sse_close=\"close\",\n",
    "            hx_swap=\"innerHTML\",\n",
    "        ).__html__() +\n",
    "        _chat_input().__html__()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1001f4191f15d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "# arena_agent.py  ── only the SSE helpers + endpoint changed\n",
    "# ------------------------------------------------------------------\n",
    "import json\n",
    "from starlette.responses import StreamingResponse     # ← instead of EventSourceResponse\n",
    "...\n",
    "\n",
    "# ── helpers --------------------------------------------------------\n",
    "def _sse(event: str, payload: str) -> str:\n",
    "    \"\"\"\n",
    "    Return one correctly-formatted Server-Sent-Events block.\n",
    "\n",
    "    Each logical message must be terminated with a *blank* line, otherwise\n",
    "    the browser keeps buffering and the event never reaches the JS side.\n",
    "    \"\"\"\n",
    "    # HTMX’ sse.js is happy with plain HTML, so we don’t wrap in JSON here.\n",
    "    body = \"\\n\".join(f\"data: {line}\" for line in payload.splitlines())\n",
    "    return f\"event: {event}\\n{body}\\n\\n\"\n",
    "\n",
    "\n",
    "async def _stream_reply(idx: int) -> AsyncIterator[str]:\n",
    "    \"\"\"Generate the assistant’s reply as an SSE stream for one chat bubble.\"\"\"\n",
    "    # ── find the user prompt that precedes this assistant placeholder ──\n",
    "    async with MSG_LOCK:\n",
    "        if idx <= 0 or idx >= len(MSG):\n",
    "            return                                       # nothing to stream\n",
    "        prompt_html = MSG[idx - 1][\"content\"]\n",
    "\n",
    "    # ── run the LLM agent ─────────────────────────────────────────────\n",
    "    reply_html = await _assistant_html(prompt_html)\n",
    "\n",
    "    # ── persist the reply so a page reload shows the whole history ────\n",
    "    async with MSG_LOCK:\n",
    "        MSG[idx][\"content\"] = reply_html\n",
    "\n",
    "    # ── 1) send it as a “message” event for htmx-ext-sse to swap in ───\n",
    "    yield _sse(\"message\", reply_html)\n",
    "\n",
    "    # ── 2) immediately tell htmx to close the EventSource connection ─\n",
    "    yield \"event: close\\ndata:\\n\\n\"\n",
    "\n",
    "\n",
    "# ── /stream/{idx} endpoint (SSE) ------------------------------------------\n",
    "@app_html.get(\"/stream/{idx}\")\n",
    "async def stream(idx: int):\n",
    "    \"\"\"\n",
    "    Streaming endpoint used by the chat bubbles (`hx-ext=\"sse\"`).\n",
    "    HTMX opens the connection, waits for the first “message” event,\n",
    "    swaps the payload into the bubble, then receives a “close” event\n",
    "    and disposes the EventSource.\n",
    "    \"\"\"\n",
    "    return StreamingResponse(\n",
    "        _stream_reply(idx),\n",
    "        media_type=\"text/event-stream\",     # <- *crucial* for EventSource\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02a8a6561a1d3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de90177e4850eab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b8ede4e8e11fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6048b03be8f0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "id": "7d230c6466190634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
