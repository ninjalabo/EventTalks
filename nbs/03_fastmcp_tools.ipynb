{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc52d2d93b18a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp fastmcp_tools\n",
    "#| test: false\n",
    "\n",
    "#\"\"\"Shared FastMCP SSE server exposing parking & route tools.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e10026fa404f4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'osrm_bike' from 'DataTalks.api_clients' (/home/nata/DataTalks/DataTalks/api_clients.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[341]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfastmcp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastMCP  \n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDataTalks\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparking_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     14\u001b[39m     nearest_parking_ids,\n\u001b[32m     15\u001b[39m     parking_status,\n\u001b[32m     16\u001b[39m     facility_prediction,\n\u001b[32m     17\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDataTalks\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi_clients\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     Point,\n\u001b[32m     21\u001b[39m     osrm_car,\n\u001b[32m     22\u001b[39m     osrm_walk,\n\u001b[32m     23\u001b[39m     osrm_bike,\n\u001b[32m     24\u001b[39m     digitransit_pt,\n\u001b[32m     25\u001b[39m     geocode, Route\n\u001b[32m     26\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'osrm_bike' from 'DataTalks.api_clients' (/home/nata/DataTalks/DataTalks/api_clients.py)"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "import logging, itertools, json, re\n",
    "from functools import lru_cache\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any\n",
    "from DataTalks.api_clients import Mode as Route_Mode\n",
    "import httpx, yaml\n",
    "from fastmcp import FastMCP  \n",
    "\n",
    "\n",
    "from DataTalks.parking_tools import (\n",
    "    nearest_parking_ids,\n",
    "    parking_status,\n",
    "    facility_prediction,\n",
    ")\n",
    "\n",
    "from DataTalks.api_clients import (\n",
    "    Point,\n",
    "    osrm_car,\n",
    "    osrm_walk,\n",
    "    osrm_bike,\n",
    "    digitransit_pt,\n",
    "    geocode, Route\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d16b58e98970607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "mcp = FastMCP(name=\"tools\")\n",
    "app = mcp.http_app(transport=\"sse\", path=\"/sse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382dba8ba56993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "INDEX_URL = \"https://api.apis.guru/v2/list.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35650d85549d7692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "import re, httpx, yaml, json\n",
    "\n",
    "\n",
    "VALID = re.compile(r\"[^a-zA-Z0-9_-]\")\n",
    "\n",
    "def load_and_clean_spec(url: str) -> dict:\n",
    "    text = httpx.get(url, timeout=30).text\n",
    "    spec = yaml.safe_load(text) if url.endswith((\".yml\", \".yaml\")) else json.loads(text)\n",
    "    for path, methods in spec[\"paths\"].items():\n",
    "        for verb, op in methods.items():\n",
    "            # ensure an operationId exists\n",
    "            op_id = op.get(\"operationId\") or f\"{verb}_{path.strip('/').replace('/','_')}\"\n",
    "            op_id = VALID.sub(\"_\", op_id)[:64]           # ðŸ”‘  clean + truncate\n",
    "            op[\"operationId\"] = op_id.lower()\n",
    "    return spec                         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec636f89d77417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "\n",
    "_VALID_RE   = re.compile(r\"^[a-zA-Z0-9_-]{1,64}$\")\n",
    "_SANITIZE_RE = re.compile(r\"[^a-zA-Z0-9_-]\")\n",
    "\n",
    "def _clean(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Return a schema-compliant tool name (letters, digits, _-, â‰¤64 chars).\n",
    "    Dots/slashes/spaces â†’ â€œ_â€; consecutive underscores collapsed.\n",
    "    \"\"\"\n",
    "    cleaned = _SANITIZE_RE.sub(\"_\", name)           # illegal â†’ _\n",
    "    cleaned = re.sub(r\"__+\", \"_\", cleaned)          # collapse runs\n",
    "    return cleaned[:64] or \"t\"                      # never empty\n",
    "\n",
    "def _dedupe(names: set[str], base: str) -> str:\n",
    "    \"\"\"If *base* already exists, append '_1', '_2' etc. until unique.\"\"\"\n",
    "    if base not in names:\n",
    "        return base\n",
    "    for i in itertools.count(1):\n",
    "        candidate = f\"{base}_{i}\"\n",
    "        if candidate not in names and len(candidate) <= 64:\n",
    "            return candidate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b39123c7ed0b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "\n",
    "SPEC_CACHE: Dict[str, dict] = {}\n",
    "\n",
    "@lru_cache\n",
    "def _get_index() -> Dict[str, dict]:\n",
    "    return httpx.get(INDEX_URL, timeout=10).json()\n",
    "\n",
    "def _score(title: str, query: str) -> float:\n",
    "    q, t = query.lower(), title.lower()\n",
    "    return (q in t) * 5 + sum(w in t for w in q.split())\n",
    "\n",
    "def _pick_spec_url(ver: dict) -> str | None:\n",
    "    \"\"\"Return the best downloadable spec URL or None if absent.\"\"\"\n",
    "    return (\n",
    "        ver.get(\"openapiUrl\")      # OpenAPI 3+\n",
    "        or ver.get(\"swaggerUrl\")   # Swagger 2.0\n",
    "        or ver.get(\"link\")         # catch-all (rare)\n",
    "    )\n",
    "\n",
    "def _requires_credentials(spec: dict) -> bool:\n",
    "    \"\"\"Return *True* if the OpenAPI spec declares any mandatory security.\n",
    "\n",
    "    Logic (conservative â€“ errs on the side of *requiring* auth):\n",
    "    â€¢ If *components.securitySchemes* is **missing** â†’ assume *no* creds.\n",
    "    â€¢ Else, if the global *security* list is **present & nonâ€‘empty* â†’ creds.\n",
    "    â€¢ Else, scan every operation for a nonâ€‘empty *security* list â†’ creds.\n",
    "\n",
    "    We donâ€™t attempt to be clever about *optional* auth â€“ thatâ€™s rarely used\n",
    "    in public APIs and would require heuristic scoring beyond this scope.\n",
    "    \"\"\"\n",
    "\n",
    "    if not spec.get(\"components\", {}).get(\"securitySchemes\"):\n",
    "        return False \n",
    "\n",
    "    # Global requirement?\n",
    "    if spec.get(\"security\"):\n",
    "        return True\n",
    "\n",
    "    # Operationâ€‘level requirement?\n",
    "    for path_item in spec.get(\"paths\", {}).values():\n",
    "        for verb, operation in path_item.items():\n",
    "            if isinstance(operation, dict) and operation.get(\"security\"):\n",
    "                return True\n",
    "\n",
    "    return False \n",
    "\n",
    "\n",
    "\n",
    "def search_public_apis(query: str, limit: int = 10) -> List[Dict]:\n",
    "    \"\"\"Return at most *limit* APIs whose specs **donâ€™t** require creds.\"\"\"\n",
    "\n",
    "    idx = _get_index()\n",
    "    # Rough relevance score identical to the original helper\n",
    "    def __score(title: str, q: str) -> float:\n",
    "        ql, tl = q.lower(), title.lower()\n",
    "        return (ql in tl) * 5 + sum(w in tl for w in ql.split())\n",
    "\n",
    "    ranked: List[tuple[str, str, str]] = sorted(\n",
    "        (\n",
    "            (api_id, ver_meta[\"info\"][\"title\"], _pick_spec_url(ver_meta))\n",
    "            for api_id, meta in idx.items()\n",
    "            if (ver_meta := meta[\"versions\"][meta[\"preferred\"]])  # := 3.8+\n",
    "        ),\n",
    "        key=lambda t: __score(t[1], query),\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "    # Keep only specs that have a downloadable URL *and* require no auth\n",
    "    results: List[Dict] = []\n",
    "    for api_id, title, spec_url in ranked:\n",
    "        if not spec_url:\n",
    "            continue\n",
    "        try:\n",
    "            spec = httpx.get(spec_url, timeout=8).json()  # small JSON files\n",
    "        except Exception:\n",
    "            continue  # skip broken links silently\n",
    "        if _requires_credentials(spec):\n",
    "            continue\n",
    "        results.append({\"id\": api_id, \"title\": title, \"spec_url\": spec_url})\n",
    "        if len(results) >= limit:\n",
    "            break\n",
    "    return results\n",
    "\n",
    "\n",
    "async def _load_openapi_spec(url: str) -> dict:\n",
    "    if url in SPEC_CACHE:\n",
    "        return SPEC_CACHE[url]\n",
    "    async with httpx.AsyncClient(timeout=10) as cx:\n",
    "        res = await cx.get(url)\n",
    "    res.raise_for_status()\n",
    "    SPEC_CACHE[url] = yaml.safe_load(res.text)\n",
    "    return SPEC_CACHE[url]\n",
    "\n",
    "\n",
    "# fastmcp_tools.py  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from pydantic import ValidationError \n",
    "\n",
    "\n",
    "@mcp.tool(\n",
    "    name=\"mount_openapi\",\n",
    "    description=(\n",
    "        \"Mount an OpenAPI or Swagger spec so its operations become callable \"\n",
    "        \"tools. Args: name, spec_url, base_url (optional), http_timeout (s).\"\n",
    "    ),\n",
    ")\n",
    "async def mount_openapi(\n",
    "    *,\n",
    "    name: str,\n",
    "    spec_url: str,\n",
    "    base_url: str | None = None,\n",
    "    http_timeout: float = 10.0,\n",
    "    mcp_root: object | None = None,      # injected by FastMCP, may be omitted\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Downloads `spec_url`, validates it, converts every operation into a\n",
    "    FastMCP tool and mounts the sub-server under `/{name}`.\n",
    "\n",
    "    Returns the list of newly created **tool names**.\n",
    "    Raises ToolError if the spec is invalid or an upstream URL cannot be\n",
    "    inferred â€“ the calling agent can catch this and try another API.\n",
    "    \"\"\"\n",
    "    # â”€â”€ 1. download & validate spec â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    try:\n",
    "        spec = await _load_openapi_spec(spec_url)          # your cached helper\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Could not fetch spec ({e})\")\n",
    "\n",
    "    # â”€â”€ 2. ensure every op has operationId â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    HTTP_VERBS = {\"get\", \"put\", \"post\", \"delete\", \"options\",\n",
    "                  \"head\", \"patch\", \"trace\"}\n",
    "    for path, methods in spec.get(\"paths\", {}).items():\n",
    "        slug = path.strip(\"/\").replace(\"/\", \"_\")\n",
    "        for verb, op in methods.items():\n",
    "            if verb.lower() not in HTTP_VERBS or not isinstance(op, dict):\n",
    "                continue\n",
    "            op.setdefault(\"operationId\", f\"{verb}_{slug}\")\n",
    "\n",
    "    # â”€â”€ 3. determine upstream base-URL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def _infer_upstream_from_swagger2(sw: dict) -> str | None:\n",
    "        host = sw.get(\"host\")\n",
    "        if not host:\n",
    "            return None\n",
    "        scheme = (sw.get(\"schemes\") or [\"https\"])[0]\n",
    "        return f\"{scheme}://{host}{sw.get('basePath', '')}\"\n",
    "\n",
    "    upstream = (\n",
    "        base_url\n",
    "        or spec.get(\"servers\", [{}])[0].get(\"url\")           # OpenAPI 3.*\n",
    "        or _infer_upstream_from_swagger2(spec)               # Swagger 2.0\n",
    "    )\n",
    "    if not upstream:\n",
    "        raise Exception(\"Cannot determine upstream URL (no servers / host).\")\n",
    "    \n",
    "    spec = load_and_clean_spec(spec)\n",
    "\n",
    "    # â”€â”€ 4. build HTTP client & sub-server â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    client = httpx.AsyncClient(base_url=upstream, timeout=http_timeout)\n",
    "    try:\n",
    "        sub = FastMCP.from_openapi(\n",
    "            openapi_spec=spec,\n",
    "            client=client,\n",
    "            name=name,\n",
    "            all_routes_as_tools=True,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to build FastMCP server: {e}\") from e\n",
    "\n",
    "    # flag for UI (does the spec declare any securitySchemes?)\n",
    "    sub.requires_auth = bool(spec.get(\"components\", {}).get(\"securitySchemes\"))\n",
    "    \n",
    "    # â”€â”€ 5. mount on the root router and return tool names â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    (mcp_root or mcp).mount(name, sub)\n",
    "    \n",
    "    # â”€â”€ 5.b ensure resulting tool names obey OpenAI pattern â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    valid_names: set[str] = {t.name for t in (await sub.get_tools()).values()}\n",
    "    for t in (await sub.get_tools()).values():\n",
    "        if _VALID_RE.match(t.name):\n",
    "            continue\n",
    "        new_name = _dedupe(valid_names, _clean(t.name))\n",
    "        t.name = new_name\n",
    "        valid_names.add(new_name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return [t.name for t in (await sub.get_tools()).values()]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "@mcp.tool(\n",
    "    name=\"quick_mount_openapi\",\n",
    "    description=(\n",
    "        \"Search the public-API index by keyword and mount the first spec that \"\n",
    "        \"doesnâ€™t require credentials.\"\n",
    "    ),\n",
    ")\n",
    "async def quick_mount_openapi(\n",
    "    query: str,\n",
    "    mcp_root: object | None = None,   # optional override for tests / sub-routers\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    1. Search the APIs-Guru index for *public* specs (no security schemes)\n",
    "       matching **query**.\n",
    "    2. Try them one by one until `mount_openapi` succeeds; return the list of\n",
    "       newly created tool names.\n",
    "    3. If none mount successfully, return `[]` **and** stash a list of\n",
    "       candidate APIs that *do* require creds in\n",
    "       `mcp_root.state[\"needs_creds\"]` so the UI can prompt the user.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1ï¸âƒ£  Try at most 10 public hits\n",
    "    for hit in search_public_apis(query, limit=10):\n",
    "        try:\n",
    "            slug = re.sub(r\"[^a-z0-9_]+\", \"_\", hit[\"id\"].lower())[:30]\n",
    "            return await mount_openapi(          # â† async + await\n",
    "                name=slug,\n",
    "                spec_url=hit[\"spec_url\"],\n",
    "                mcp_root=mcp_root,\n",
    "            )\n",
    "        except Exception:\n",
    "            continue          # keep trying next candidate\n",
    "\n",
    "    # 2ï¸âƒ£  Nothing mounted â†’ gather *all* candidates (public or not)\n",
    "    candidates: List[Dict[str, Any]] = []\n",
    "    for api_id, meta in _get_index().items():\n",
    "        ver_meta = meta[\"versions\"][meta[\"preferred\"]]\n",
    "        spec_url = _pick_spec_url(ver_meta)\n",
    "        if not spec_url:\n",
    "            continue\n",
    "        candidates.append({\n",
    "            \"id\": api_id,\n",
    "            \"title\": ver_meta[\"info\"][\"title\"],\n",
    "            \"spec_url\": spec_url,\n",
    "            \"needs_credentials\": True,   # we already tried the public ones\n",
    "        })\n",
    "\n",
    "    if mcp_root is not None:\n",
    "        # ensure a consistent place for the UI/agent to inspect\n",
    "        mcp_root.state[\"needs_creds\"] = candidates\n",
    "\n",
    "    return []   # signal to the agent/UI that mounting failed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acaaba36f40f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "async def _load_specs() -> None:\n",
    "    \"\"\"Warm the APIs.guru index and log a preview (first 10 records).\"\"\"\n",
    "    index: dict = _get_index()          # synchronous helper you already wrote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a41c87d3d73a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "async def car_route(\n",
    "    src_lat: float, src_lon: float,\n",
    "    dst_lat: float, dst_lon: float,\n",
    ") -> Route:\n",
    "    \"Car route via public OSRM demo.\"\n",
    "    return await osrm_car(Point(lat=src_lat, lon=src_lon),\n",
    "                          Point(lat=dst_lat, lon=dst_lon))\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "async def walk_route(\n",
    "    src_lat: float, src_lon: float,\n",
    "    dst_lat: float, dst_lon: float,\n",
    ") -> Route:\n",
    "    \"Walking route via OSRM.\"\n",
    "    return await osrm_walk(Point(lat=src_lat, lon=src_lon),\n",
    "                           Point(lat=dst_lat, lon=dst_lon))\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "async def bike_route(\n",
    "    src_lat: float, src_lon: float,\n",
    "    dst_lat: float, dst_lon: float,\n",
    ") -> Route:\n",
    "    \"Walking route via OSRM.\"\n",
    "    return await osrm_bike(Point(lat=src_lat, lon=src_lon),\n",
    "                           Point(lat=dst_lat, lon=dst_lon))\n",
    "\n",
    "@mcp.tool()\n",
    "async def public_transport_route(\n",
    "    src_lat: float, src_lon: float,\n",
    "    dst_lat: float, dst_lon: float,\n",
    "    dataset: str = \"hsl\",\n",
    ") -> Route:\n",
    "    \"\"\"Fastest public-transport itinerary via Digitransit Routing v2.\"\"\"\n",
    "    return await digitransit_pt(Point(lat=src_lat, lon=src_lon),\n",
    "                                Point(lat=dst_lat, lon=dst_lon),\n",
    "                                dataset=dataset)\n",
    "\n",
    "@mcp.tool()\n",
    "async def geocode_osm(query: str) -> dict:\n",
    "    \"\"\"First OpenStreetMap location match for *query*.\"\"\"\n",
    "    try:\n",
    "        return (await geocode(query)).model_dump()\n",
    "    except LookupError as e:\n",
    "        # surface a predictable ToolError so the agent can fall back\n",
    "        raise ValueError(str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57a997ceb57741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "@mcp.tool()\n",
    "async def nearest_parking(\n",
    "    lat: float, lon: float, radius_m: int = 800\n",
    ") -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Return `{capacityType: facility_id}` for the closest facilities\n",
    "    within *radius_m* metres of (*lat*, *lon*).\n",
    "    \"\"\"\n",
    "    return await nearest_parking_ids(lat, lon, radius_m=radius_m)\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "async def urheilupuisto_parking_status(\n",
    "    facility_id: int = 285,                  # Urheilupuisto default\n",
    "    capacity_type: str = \"CAR\",\n",
    "    usage: str = \"PARK_AND_RIDE\",\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    **Parking only.** Returns real-time utilisation of a *Fintraffic* facility.\n",
    "    Not related to weather or other live data.\n",
    "    \"\"\"\n",
    "    return await parking_status(\n",
    "        facility_id,\n",
    "        capacity_type=capacity_type,\n",
    "        usage=usage,\n",
    "    )\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "async def urheilupuisto_parking_forecast(\n",
    "    facility_id: int = 285,\n",
    "    hours: int = 24,\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Fintraffic capacity forecast for *facility_id* over the next *hours*.\n",
    "    \"\"\"\n",
    "    return await facility_prediction(facility_id, hours=hours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b47349c87401c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "@dataclass\n",
    "class SegmentEmission:\n",
    "    mode: Route_Mode\n",
    "    distance_m: float\n",
    "    co2e_g: float\n",
    "\n",
    "@dataclass\n",
    "class TripEmissionEstimate:\n",
    "    segments: List[SegmentEmission]\n",
    "    total_distance_m: float\n",
    "    total_co2e_g: float\n",
    "\n",
    "_EMISSION_FACTORS: dict[str, float] = {\n",
    "    \"car\" : 171.0,\n",
    "    \"bike\": 21.0,\n",
    "    \"walk\": 56.0,\n",
    "    \"pt\"  :  65.0,   # typical urban-public-transport mix (bus+rail)\n",
    "}\n",
    "\n",
    "@mcp.tool(\n",
    "    name=\"estimate_trip_emissions\",\n",
    "    description=(\n",
    "        \"Given a list of Route objects that form a multimodal trip, return \"\n",
    "        \"segment-by-segment and total COâ‚‚-e estimates using average factors.\"\n",
    "    ),\n",
    ")\n",
    "def estimate_trip_emissions(routes: List[Route]) -> TripEmissionEstimate:\n",
    "    segs: List[SegmentEmission] = []\n",
    "    for rt in routes:\n",
    "        factor = _EMISSION_FACTORS.get(rt.mode, 0.0) \n",
    "        co2_g  = factor * (rt.distance_m / 1000)\n",
    "        segs.append(SegmentEmission(rt.mode, rt.distance_m, co2_g))\n",
    "\n",
    "    total_d = sum(s.distance_m for s in segs)\n",
    "    total_c = sum(s.co2e_g     for s in segs)\n",
    "\n",
    "    return TripEmissionEstimate(\n",
    "        segments=segs,\n",
    "        total_distance_m=total_d,\n",
    "        total_co2e_g=total_c,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b50e245f6f7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d39960850bc4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "id": "5e4e5e34d907772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
